{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(\"GOP_DATASET.csv\",encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate:confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn:confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter:confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I_Am_Kenzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/7/15 9:54</td>\n",
       "      <td>6.296970e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PeacefulQuest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/7/15 9:54</td>\n",
       "      <td>6.296970e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PussssyCroook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/7/15 9:54</td>\n",
       "      <td>6.296970e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MattFromTexas31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/7/15 9:54</td>\n",
       "      <td>6.296970e+17</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sharonDay5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/7/15 9:54</td>\n",
       "      <td>6.296970e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                candidate  candidate:confidence relevant_yn  \\\n",
       "0  No candidate mentioned                   1.0         yes   \n",
       "1            Scott Walker                   1.0         yes   \n",
       "2  No candidate mentioned                   1.0         yes   \n",
       "3  No candidate mentioned                   1.0         yes   \n",
       "4            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn:confidence sentiment  sentiment:confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter:confidence candidate_gold             name relevant_yn_gold  \\\n",
       "0                     1.0000            NaN       I_Am_Kenzi              NaN   \n",
       "1                     1.0000            NaN    PeacefulQuest              NaN   \n",
       "2                     0.6629            NaN    PussssyCroook              NaN   \n",
       "3                     0.7039            NaN  MattFromTexas31              NaN   \n",
       "4                     1.0000            NaN       sharonDay5              NaN   \n",
       "\n",
       "   retweet_count sentiment_gold subject_matter_gold  \\\n",
       "0              5            NaN                 NaN   \n",
       "1             26            NaN                 NaN   \n",
       "2             27            NaN                 NaN   \n",
       "3            138            NaN                 NaN   \n",
       "4            156            NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "  tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0   8/7/15 9:54  6.296970e+17            NaN                       Quito  \n",
       "1   8/7/15 9:54  6.296970e+17            NaN                         NaN  \n",
       "2   8/7/15 9:54  6.296970e+17            NaN                         NaN  \n",
       "3   8/7/15 9:54  6.296970e+17          Texas  Central Time (US & Canada)  \n",
       "4   8/7/15 9:54  6.296970e+17            NaN                     Arizona  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.drop(['candidate','candidate:confidence','relevant_yn',\n",
    "              'relevant_yn:confidence','sentiment:confidence',\n",
    "              'subject_matter','subject_matter:confidence',\n",
    "              'candidate_gold','name','relevant_yn_gold',\n",
    "              'retweet_count','sentiment_gold','subject_matter_gold',\n",
    "              'tweet_coord','tweet_created','tweet_id',\n",
    "              'tweet_location','user_timezone'],axis= 1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @NancyOsborne180: Last night's debate prove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   Neutral  RT @NancyLeeGrahn: How did everyone feel about...\n",
       "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "2   Neutral  RT @TJMShow: No mention of Tamir Rice and the ...\n",
       "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
       "5  Positive  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
       "6  Negative  RT @warriorwoman91: I liked her and was happy ...\n",
       "7   Neutral  Going on #MSNBC Live with @ThomasARoberts arou...\n",
       "8  Negative  Deer in the headlights RT @lizzwinstead: Ben C...\n",
       "9  Negative  RT @NancyOsborne180: Last night's debate prove..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   Neutral  RT @NancyLeeGrahn: How did everyone feel about...\n",
       "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "2   Neutral  RT @TJMShow: No mention of Tamir Rice and the ...\n",
       "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={'sentiment':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @NancyOsborne180: Last night's debate prove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0   Neutral  RT @NancyLeeGrahn: How did everyone feel about...\n",
       "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
       "2   Neutral  RT @TJMShow: No mention of Tamir Rice and the ...\n",
       "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
       "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
       "5  Positive  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
       "6  Negative  RT @warriorwoman91: I liked her and was happy ...\n",
       "7   Neutral  Going on #MSNBC Live with @ThomasARoberts arou...\n",
       "8  Negative  Deer in the headlights RT @lizzwinstead: Ben C...\n",
       "9  Negative  RT @NancyOsborne180: Last night's debate prove..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['text'].apply(lambda x: x.lower())\n",
    "dataset['text'] = dataset['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>rt nancyleegrahn how did everyone feel about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>rt scottwalker didnt catch the full gopdebate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>rt tjmshow no mention of tamir rice and the go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>rt robgeorge that carly fiorina is trending  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>rt danscavino gopdebate w realdonaldtrump deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>rt gregabbott_tx tedcruz on my first day i wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>rt warriorwoman91 i liked her and was happy wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>going on msnbc live with thomasaroberts around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>deer in the headlights rt lizzwinstead ben car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>rt nancyosborne180 last nights debate proved i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0   Neutral  rt nancyleegrahn how did everyone feel about t...\n",
       "1  Positive  rt scottwalker didnt catch the full gopdebate ...\n",
       "2   Neutral  rt tjmshow no mention of tamir rice and the go...\n",
       "3  Positive  rt robgeorge that carly fiorina is trending  h...\n",
       "4  Positive  rt danscavino gopdebate w realdonaldtrump deli...\n",
       "5  Positive  rt gregabbott_tx tedcruz on my first day i wil...\n",
       "6  Negative  rt warriorwoman91 i liked her and was happy wh...\n",
       "7   Neutral  going on msnbc live with thomasaroberts around...\n",
       "8  Negative  deer in the headlights rt lizzwinstead ben car...\n",
       "9  Negative  rt nancyosborne180 last nights debate proved i..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['text'].map(lambda x: x.lstrip('rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>nancyleegrahn how did everyone feel about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>scottwalker didnt catch the full gopdebate la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>tjmshow no mention of tamir rice and the gopd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>robgeorge that carly fiorina is trending  hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>danscavino gopdebate w realdonaldtrump delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>gregabbott_tx tedcruz on my first day i will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>warriorwoman91 i liked her and was happy when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>going on msnbc live with thomasaroberts around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>deer in the headlights rt lizzwinstead ben car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>nancyosborne180 last nights debate proved it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0   Neutral   nancyleegrahn how did everyone feel about the...\n",
       "1  Positive   scottwalker didnt catch the full gopdebate la...\n",
       "2   Neutral   tjmshow no mention of tamir rice and the gopd...\n",
       "3  Positive   robgeorge that carly fiorina is trending  hou...\n",
       "4  Positive   danscavino gopdebate w realdonaldtrump delive...\n",
       "5  Positive   gregabbott_tx tedcruz on my first day i will ...\n",
       "6  Negative   warriorwoman91 i liked her and was happy when...\n",
       "7   Neutral  going on msnbc live with thomasaroberts around...\n",
       "8  Negative  deer in the headlights rt lizzwinstead ben car...\n",
       "9  Negative   nancyosborne180 last nights debate proved it ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target                                               text\n",
      "0       1   nancyleegrahn how did everyone feel about the...\n",
      "1       1   scottwalker didnt catch the full gopdebate la...\n",
      "2       1   tjmshow no mention of tamir rice and the gopd...\n",
      "3       1   robgeorge that carly fiorina is trending  hou...\n",
      "4       1   danscavino gopdebate w realdonaldtrump delive...\n",
      "5       1   gregabbott_tx tedcruz on my first day i will ...\n",
      "6       0   warriorwoman91 i liked her and was happy when...\n",
      "7       1  going on msnbc live with thomasaroberts around...\n",
      "8       0  deer in the headlights rt lizzwinstead ben car...\n",
      "9       0   nancyosborne180 last nights debate proved it ...\n"
     ]
    }
   ],
   "source": [
    "dataset['target']=dataset['target'].apply(lambda x: 0 if x=='Negative' else 1)\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13871 entries, 0 to 13870\n",
      "Data columns (total 2 columns):\n",
      "target    13871 non-null int64\n",
      "text      13871 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 216.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.reset_index(drop=True,inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = dataset.text\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahilarora/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 13593 entries with 61.21% negative, 38.79% positive\n",
      "Validation set has total 139 entries with 61.87% negative, 38.13% positive\n",
      "Test set has total 139 entries with 62.59% negative, 37.41% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
    "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
    "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))\n",
    "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
    "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8493\n",
      "1    5378\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Sent_Count = dataset['target'].value_counts()\n",
    "\n",
    "print(Sent_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelize_tweets_ug(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13871/13871 [00:00<00:00, 1159895.35it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_cbow = Word2Vec(sg=0, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13871/13871 [00:00<00:00, 1225134.58it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1447603.65it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1356316.37it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1379111.34it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 933765.46it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1238698.49it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1391147.77it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1438298.91it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1187063.94it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1453389.73it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1337360.43it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1231019.04it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1409243.07it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1346179.62it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1424284.93it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1427184.86it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1409926.10it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1466283.35it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1424529.05it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1356189.91it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1391846.67it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1535597.72it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1527654.42it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1530346.71it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1406211.56it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1529019.47it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1345899.34it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1510520.06it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1518087.64it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1422369.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 721 ms, total: 5min 32s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_cbow.alpha -= 0.002\n",
    "    model_ug_cbow.min_alpha = model_ug_cbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13871/13871 [00:00<00:00, 1226529.30it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_sg = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13871/13871 [00:00<00:00, 1251003.97it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1310548.75it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1187694.00it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1355084.33it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1525491.39it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1509814.47it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1425296.82it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1434999.65it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1367956.52it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1431328.04it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1546372.98it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1487806.64it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1393246.58it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1235384.35it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1417448.92it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1424982.63it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1206386.41it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1415379.90it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1405362.36it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1402651.79it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1433090.89it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1526451.98it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1426310.14it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1421084.29it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1409618.66it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1274908.86it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1441291.95it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1473301.19it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1409379.62it/s]\n",
      "100%|██████████| 13871/13871 [00:00<00:00, 1419039.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 31s, sys: 1.02 s, total: 12min 32s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_sg.alpha -= 0.002\n",
    "    model_ug_sg.min_alpha = model_ug_sg.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ug_cbow.save('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg.save('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "\n",
    "model.save('model_lstm.word2vec')\n",
    "model.save('model_lstm.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load('model_lstm.word2vec')\n",
    "model = KeyedVectors.load('model_lstm.word2vec')\n",
    "\n",
    "polarity = model.predict(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_ug_cbow = KeyedVectors.load('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg = KeyedVectors.load('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7858"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_ug_cbow.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7858 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_ug_cbow.wv.vocab.keys():\n",
    "    embeddings_index[w] = np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19344"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " supermanhotmale dear gov walker you have nothing to brag about you fucked your state of wisconsin and you suck koch bitchasspoli_\n",
      "if the only outcome of the gopdebate is that the trump is a domineering boor replace one of the old guys in suits with a monkey next time\n",
      " supermanhotmale no more bushs fuck you jeb gopdebates\n",
      "llamos sprightlymagic considering which debate it was i cant blame them i might need to join them thanks gopdebate\n",
      "he first gopdebate social media reaction and more  httptcouh06ezxxfg socialmedia smo\n"
     ]
    }
   ],
   "source": [
    "for x in x_train[:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[174,\n",
       "  340,\n",
       "  540,\n",
       "  170,\n",
       "  12,\n",
       "  32,\n",
       "  355,\n",
       "  4,\n",
       "  1758,\n",
       "  21,\n",
       "  12,\n",
       "  975,\n",
       "  86,\n",
       "  380,\n",
       "  5,\n",
       "  849,\n",
       "  8,\n",
       "  12,\n",
       "  1115,\n",
       "  667,\n",
       "  2077],\n",
       " [54,\n",
       "  2,\n",
       "  103,\n",
       "  3312,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  17,\n",
       "  2,\n",
       "  15,\n",
       "  6,\n",
       "  7,\n",
       "  7754,\n",
       "  7755,\n",
       "  976,\n",
       "  60,\n",
       "  5,\n",
       "  2,\n",
       "  558,\n",
       "  338,\n",
       "  10,\n",
       "  2508,\n",
       "  42,\n",
       "  7,\n",
       "  5086,\n",
       "  102,\n",
       "  99],\n",
       " [174, 63, 73, 1255, 583, 12, 58, 3],\n",
       " [7756,\n",
       "  7757,\n",
       "  1208,\n",
       "  323,\n",
       "  23,\n",
       "  14,\n",
       "  22,\n",
       "  9,\n",
       "  139,\n",
       "  1656,\n",
       "  107,\n",
       "  9,\n",
       "  651,\n",
       "  88,\n",
       "  4,\n",
       "  1015,\n",
       "  107,\n",
       "  211,\n",
       "  1],\n",
       " [24, 209, 1, 264, 331, 1043, 8, 73, 7758, 1917, 7759]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13593, 45)\n"
     ]
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=45)\n",
    "print('Shape of data tensor:', x_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  174,  340,  540,  170,   12,   32,  355,    4, 1758,\n",
       "          21,   12,  975,   86,  380,    5,  849,    8,   12, 1115,  667,\n",
       "        2077],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,   54,    2,  103, 3312,    5,\n",
       "           2,    1,    6,   17,    2,   15,    6,    7, 7754, 7755,  976,\n",
       "          60,    5,    2,  558,  338,   10, 2508,   42,    7, 5086,  102,\n",
       "          99],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  174,   63,   73, 1255,  583,   12,   58,\n",
       "           3],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 7756, 7757, 1208,  323,   23,   14,   22,\n",
       "           9,  139, 1656,  107,    9,  651,   88,    4, 1015,  107,  211,\n",
       "           1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   24,  209,    1,  264,  331, 1043,    8,   73, 7758, 1917,\n",
       "        7759]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
    "x_val_seq = pad_sequences(sequences_val, maxlen=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(embedding_matrix[6] ,embeddings_index.get('walker'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 7\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13593 samples, validate on 139 samples\n",
      "Epoch 1/5\n",
      "22s - loss: 0.5802 - acc: 0.6890 - val_loss: 0.5490 - val_acc: 0.7410\n",
      "Epoch 2/5\n",
      "22s - loss: 0.4613 - acc: 0.7856 - val_loss: 0.5126 - val_acc: 0.7266\n",
      "Epoch 3/5\n",
      "22s - loss: 0.3289 - acc: 0.8738 - val_loss: 0.6272 - val_acc: 0.6978\n",
      "Epoch 4/5\n",
      "22s - loss: 0.2399 - acc: 0.9194 - val_loss: 0.6871 - val_acc: 0.7266\n",
      "Epoch 5/5\n",
      "22s - loss: 0.2114 - acc: 0.9287 - val_loss: 0.6309 - val_acc: 0.7554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152454828>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ptw2v = Sequential()\n",
    "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=45, trainable=False)\n",
    "model_ptw2v.add(e)\n",
    "model_ptw2v.add(Flatten())\n",
    "model_ptw2v.add(Dense(256, activation='relu'))\n",
    "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
    "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_ptw2v = Sequential()\n",
    "# e = Embedding(100000, 200, input_length=45)\n",
    "# model_ptw2v.add(e)\n",
    "# model_ptw2v.add(Flatten())\n",
    "# model_ptw2v.add(Dense(256, activation='relu'))\n",
    "# model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
    "# model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 45, 200)           20000000  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2304256   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 22,304,513\n",
      "Trainable params: 22,304,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ptw2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "model_ptw2v.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=[metrics.mae, metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences2 = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (139, 45)\n"
     ]
    }
   ],
   "source": [
    "x_test_seq = pad_sequences(sequences2, maxlen=45)\n",
    "print('Shape of data tensor:', x_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/139 [=====>........................] - ETA: 0sTest score: 0.653311969779\n",
      "Test accuracy: 0.733812949211\n"
     ]
    }
   ],
   "source": [
    "model_ptw2v.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "score, acc = model_ptw2v.evaluate(x_test_seq, y_test,\n",
    "                            batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 45, 200)           20000000  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 44, 100)           40100     \n",
      "=================================================================\n",
      "Total params: 20,040,100\n",
      "Trainable params: 20,040,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "# structure_test = Sequential()\n",
    "# e = Embedding(100000, 200, input_length=45)\n",
    "# structure_test.add(e)\n",
    "# structure_test.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "# structure_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 45, 200)           20000000  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 44, 100)           40100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 20,040,100\n",
      "Trainable params: 20,040,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# structure_test = Sequential()\n",
    "# e = Embedding(100000, 200, input_length=45)\n",
    "# structure_test.add(e)\n",
    "# structure_test.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "# structure_test.add(GlobalMaxPooling1D())\n",
    "# structure_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13593 samples, validate on 139 samples\n",
      "Epoch 1/5\n",
      "10s - loss: 0.5817 - acc: 0.6854 - val_loss: 0.5699 - val_acc: 0.7122\n",
      "Epoch 2/5\n",
      "9s - loss: 0.5041 - acc: 0.7542 - val_loss: 0.5507 - val_acc: 0.7050\n",
      "Epoch 3/5\n",
      "10s - loss: 0.4584 - acc: 0.7859 - val_loss: 0.5428 - val_acc: 0.7338\n",
      "Epoch 4/5\n",
      "10s - loss: 0.4156 - acc: 0.8121 - val_loss: 0.5645 - val_acc: 0.7194\n",
      "Epoch 5/5\n",
      "10s - loss: 0.3702 - acc: 0.8384 - val_loss: 0.5422 - val_acc: 0.7266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x109d0d9b0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_cnn_01 = Sequential()\n",
    "# e = Embedding(100000, 200, weights=[embedding_matrix], input_length=45, trainable=False)\n",
    "# model_cnn_01.add(e)\n",
    "# model_cnn_01.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "# model_cnn_01.add(GlobalMaxPooling1D())\n",
    "# model_cnn_01.add(Dense(256, activation='relu'))\n",
    "# model_cnn_01.add(Dense(1, activation='sigmoid'))\n",
    "# model_cnn_01.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 45)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 45, 200)       20000000    input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 44, 100)       40100       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 43, 100)       60100       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 42, 100)       80100       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalMa (None, 100)           0           conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalMa (None, 100)           0           conv1d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalMa (None, 100)           0           conv1d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 300)           0           global_max_pooling1d_3[0][0]     \n",
      "                                                                   global_max_pooling1d_4[0][0]     \n",
      "                                                                   global_max_pooling1d_5[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 256)           77056       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             257         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1)             0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20,257,613\n",
      "Trainable params: 20,257,613\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_input = Input(shape=(45,), dtype='int32')\n",
    "\n",
    "tweet_encoder = Embedding(100000, 200, weights=[embedding_matrix], input_length=45, trainable=True)(tweet_input)\n",
    "bigram_branch = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "\n",
    "merged = Dense(256, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(1)(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[tweet_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13593 samples, validate on 139 samples\n",
      "Epoch 1/5\n",
      "13568/13593 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6880Epoch 00000: val_acc improved from -inf to 0.71942, saving model to CNN_best_weights.00-0.7194.hdf5\n",
      "13593/13593 [==============================] - 229s - loss: 0.5919 - acc: 0.6880 - val_loss: 0.5475 - val_acc: 0.7194\n",
      "Epoch 2/5\n",
      "13568/13593 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.7698Epoch 00001: val_acc did not improve\n",
      "13593/13593 [==============================] - 223s - loss: 0.4775 - acc: 0.7697 - val_loss: 0.5463 - val_acc: 0.7194\n",
      "Epoch 3/5\n",
      "13568/13593 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8419Epoch 00002: val_acc improved from 0.71942 to 0.76259, saving model to CNN_best_weights.02-0.7626.hdf5\n",
      "13593/13593 [==============================] - 225s - loss: 0.3665 - acc: 0.8417 - val_loss: 0.5380 - val_acc: 0.7626\n",
      "Epoch 4/5\n",
      "13568/13593 [============================>.] - ETA: 0s - loss: 0.2637 - acc: 0.8966Epoch 00003: val_acc did not improve\n",
      "13593/13593 [==============================] - 228s - loss: 0.2641 - acc: 0.8965 - val_loss: 0.6073 - val_acc: 0.7338\n",
      "Epoch 5/5\n",
      "13568/13593 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9200Epoch 00004: val_acc did not improve\n",
      "13593/13593 [==============================] - 228s - loss: 0.1949 - acc: 0.9201 - val_loss: 0.6130 - val_acc: 0.7482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12acfcef0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"CNN_best_weights.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "model.fit(x_train_seq, y_train, batch_size=32, epochs=5,\n",
    "                     validation_data=(x_val_seq, y_validation), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/139 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.53801403907563194, 0.76258992762874356]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "loaded_CNN_model = load_model('CNN_best_weights.02-0.7626.hdf5')\n",
    "loaded_CNN_model.evaluate(x=x_val_seq, y=y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/139 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.54607616332795128, 0.76978417223306006]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=45)\n",
    "yhat_cnn = loaded_CNN_model.predict(x_test_seq)\n",
    "loaded_CNN_model.evaluate(x=x_test_seq, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
