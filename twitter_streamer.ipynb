{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TWITTER API Library\n",
    "from tweepy.api import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Access keys\n",
    "\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "\n",
    "access_token = ''\n",
    "access_token_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Tweet Classification Class\n",
    "\n",
    "class SentimentAnalyzer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    \n",
    "    def analyze_tweet_sentiment(self,tweet):\n",
    "        \n",
    "        \n",
    "        sentiment = model.predict(tweet)\n",
    "            \n",
    "        return polarity,sentiment\n",
    "    \n",
    "    def analyze_all_tweet_sentiment(self, tweet_file):\n",
    "        \n",
    "        twitter_sentiment_list = []\n",
    "        with open(tweet_file,'r') as tf:\n",
    "            for tweet in tf:\n",
    "                sentiment = self.analyze_tweet_sentiment(tweet)\n",
    "                twitter_sentiment_list.append(sentiment)                \n",
    "        return twitter_sentiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter Streaming Class\n",
    "\n",
    "\n",
    "class TwitterStreamer():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        l = StdOutListener(fetched_tweets_filename)\n",
    "        auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "        auth.set_access_token(access_token,access_token_secret)\n",
    "#         auth = OAuthHandler(config.TWITTER_CONSUMER_KEY, config.TWITTER_CONSUMER_SECRET)\n",
    "#         auth.set_access_token(config.TWITTER_ACCESS_TOKEN, config.TWITTER_ACCESS_TOKEN_SECRET)\n",
    "        stream = Stream(auth, l)\n",
    "        \n",
    "        \n",
    "\n",
    "        #This line filter Twitter Streams to capture data by the keywords: \n",
    "        stream.filter(track=hash_tag_list,languages =['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import re\n",
    "import string\n",
    "from tweepy.api import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter Final Class\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fetched_tweets_filename,api=None):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "        self.sa = SentimentAnalyzer()\n",
    "        self.api=api or API()\n",
    "\n",
    "\n",
    "    def on_status(self, data):\n",
    "#         tweet = data.split(',\"text\":\"')[1].split('\",\"source')[0]\n",
    "\n",
    "        tweet = data.text\n",
    "    \n",
    "        \n",
    "        if not tweet.startswith('RT'):\n",
    "            \n",
    "            polarity, magnitude = self.sa.analyze_tweet_sentiment(tweet)\n",
    "            tweet_and_sentiment = tweet +',' + \" POLARITY::\" + str(polarity) + \",\" + \\\n",
    "                                  \" SENTIMENT::\" + str(magnitude) + ' ###_END_OF_TWEET_###' +'\\n'             \n",
    "            print(tweet_and_sentiment)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            with open(fetched_tweets_filename,'a') as tf:\n",
    "                \n",
    "                tf.write(tweet_and_sentiment)\n",
    "                \n",
    "            \n",
    "            with open(polarity_file,'a') as pt:\n",
    "                \n",
    "                plot_point = str(polarity)+'\\n'\n",
    "                pt.write(plot_point)\n",
    "                \n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(\"Connection Error\",status)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    \n",
    "    listT = []\n",
    "    k=True\n",
    "    while k:\n",
    "        \n",
    "        ans = input(\"Enter Keywords: \")\n",
    "        listT.append(ans)\n",
    "        ans2 = input(\"Want to Add More Keywords y/n: \")\n",
    "        if ans2=='y':\n",
    "            continue\n",
    "        else:\n",
    "            print(\"###########################____FETCHING TWEETS____##################################\")\n",
    "            k=False\n",
    "        \n",
    "    \n",
    "    \n",
    "    hash_tag_list = listT\n",
    "    fetched_tweets_filename = \"stream_tweets3.txt\"\n",
    "    polarity_file = \"polarity_tweets.txt\"\n",
    "    z = 1\n",
    "\n",
    "\n",
    "    ts = TwitterStreamer()\n",
    "    ts.stream_tweets(fetched_tweets_filename, hash_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computing tweets\n",
    "\n",
    "with open(\"tweets_12.txt\") as f:\n",
    "    contents = f.read()\n",
    "    count_pos = sum(1 for x in re.finditer(r\"\\b\"+re.escape('positive')+ r\"\\b\", contents))\n",
    "    count_neg = sum(1 for x in re.finditer(r\"\\b\"+re.escape('negative')+ r\"\\b\", contents))\n",
    "    count_neut = sum(1 for x in re.finditer(r\"\\b\"+re.escape('neutral')+ r\"\\b\", contents))\n",
    "\n",
    "print(\"Count Positive:\",count_pos)\n",
    "print(\"Count Negative:\",count_neg)\n",
    "print(\"Count Neautral:\",count_neut)\n",
    "\n",
    "total = count_pos+count_neg+count_neut\n",
    "\n",
    "p_pos = float(count_pos/total)*100.00\n",
    "p_neg = float(count_neg/total)*100.00\n",
    "p_nea = float(count_neut/total)*100.00\n",
    "\n",
    "print(\"Count Positive %:\",int(p_pos),'%')\n",
    "print(\"Count Negative %:\",int(p_neg),'%')\n",
    "print(\"Count Neautral %:\",int(p_nea),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie Chart Description\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "senti_plot = [p_pos,p_neg,p_nea]\n",
    "activities = ['positive','negative','neutral']\n",
    "cols = ['g','r','b']\n",
    "\n",
    "plt.pie(senti_plot,\n",
    "        labels=activities,\n",
    "        colors=cols,\n",
    "        shadow=True,\n",
    "        startangle=90,\n",
    "        autopct='%1.1f%%')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
